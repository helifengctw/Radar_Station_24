# Radar_Station_24
Private radar station repository for CKYF Robomaster 2024

说明文档：

代码说明：
1，雷达比赛启动程序：把雷达传感器端放上雷达摆放平台，运算端放到下面，连好线。打开终端，执行scripts/sensor_qidong脚本，然后再开一个终端，执行ros2 run utilities pick_up_point命令，进行pnp选点。
2，radar24_ws中除了lidar_localization_ros2和ndt_omp_ros2完全没用到外，其他的都用到了，必须根据scripts/sensor_qidong里面的东西一个一个看。
3，雷达站有左右两个相机和一个激光雷达，相机目前是一个看远一个看近，激光雷达是几乎覆盖全场。左右两个相机的运行代码几乎一样，所以将相机驱动、yolo识别、激光雷达驱动和获取深度包放在一个ros2组件中（component_sensor_far/component_sensor_close）,两个组件的代码相同，参数和命名空间不同，其中只有一个组件驱动激光雷达，另一个组件不驱动激光雷达，只订阅重映射到该命名空间的点云话题。
4，采用组件的原因是采用进程内通信，将图像话题和识别等放在一个进程内，但是我也没具体测试组件的优化作用到底大不大。
5，雷达的工作原理和算法可以参考战队仓库的22年雷达站的开源文档。
以下是各个包的具体说明：
a、bayer_camera_driver:采用bayer格式驱动相机获得图像，这个包的关键点在于相机曝光、增益等参数的调节，调不好的话对导致图像中运动物体的拖影长，画面太暗，帧率太低等问题。
b、yolov5_detector：主要涉及yolov5、KM_matching等算法。其中有两层yolov5神经网络，分别识别相机画面中的红方和蓝方的车，和第一次网络识别到的车中的装甲板数字。采用trt部署的yolov5，是从github上tensorrtx仓库改进过来的。KM_matching是用来进行帧之间的运动预测匹配，来增强识别的连续性。最后将识别出的框和车的id发送出来。
c、get_depth：订阅激光雷达的点云话题和yolo的识别结果话题。将点云投影的相机图像画面，并根据yolo的识别框按照一定策略取出对应车的深度。最后将车的框的深度和图像坐标发送出去。
d、small_map：订阅车的框的深度和图像坐标，并将其投影到小地图坐标系上，再加以判断，筛选出敌方车辆，将车在小地图上的坐标发送出去。并根据裁判系统的一些信息进行自主决策，判断出发双倍易伤的时机，再发送出去。
e、robot_serial：串口通信包，订阅小地图的处理结果，并与裁判系统通信，收发车辆的坐标和场地信息。
f、pnp_solver：进行pnp标定的计算，订阅utilites/pick_up_point的选点消息，进行pnp计算。同时，记录并更新各个参数，在small_map启动时，为其提供所需参数以进行计算。
g、utilites：工具包，目前只有pick_up_point一个节点，用于准备阶段进行pnp选点，并将点的信息发送出去。

调试雷达需注意事项：
1，场地很重要，没有场地（篮球场大小）就没办法准确的调试，也没办法找bug，所以一定要积极的找好场地，不能往后拖，越早找好场地越好。
2，相机和雷达之间的联合标定最为繁琐，也对雷达定位的准确度其决定性作用。每个相机和雷达之间联合标定所用的数据要达到40个以上，并且最终的计算误差至少要小于4.0，标定用的大标定板要有1.5m*1m以上才准确，你想要在多大的实际范围内保证一定的定位精度，就要在多大的范围内进行标定，标定板要在相机视野的各个角落都有一定量的数据样本。标定板要用支架固定，不能人举着。标定同一距离的标定板时可以不动标定板，通过调整雷达的角度来使标定板出现在相机视野的各个地方，就免得搬来搬去那么大个标定板。
3，我的yolov5神经网络的数据集制作情况如下：第一层车的神经网络由于时间问题，只有1.3k张图像，效果还行，不会漏识别，但是重复识别和误识别的情况较多。第二层识别装甲板的神经网络数据集大概有1.5w张，识别效果还行，但是数字之间的误识别还是偶尔发送，可以考虑改进标图策略或者加一些传统视觉预处理。总之数据集的数量只能比我的多，同时要质量优先，没有质量，你再多的数据集都白搭。炼丹有很多经验小技巧，可以自己多练习练习，摸索一下。
4，雷达比赛的时候有很多注意事项，如果考虑不周，会直接影响成败。比如雷达站的机械结构，用三脚架还是其他支架支撑雷达，怎么连线、供电才能保证在比赛的准备阶段能够快速的启动雷达并保证较高的稳定和性。用三角架的话，比较轻便，好搬运，用一个方形支撑框的话，能够把框架卡在雷达摆放平台的一个角，这样就能保证雷达每次都在同一个位置。相机和雷达如果用插头供电就没办法去没电源的场地调，只有用电池供电才能在任何场景下调试。雷达之前一直是用自己的笔记本电脑跑的，如果有条件的话可以用台式机箱跑，算力更足，而且比赛会提供显示屏，但是缺点就是没办法在准备的时候提前启动程序，必须等摆到雷达摆放平台才能启动，会浪费大量时间。制作规范有尺寸要求，一切制作、设计都要按制作规范来。 
5，按照我看到的其他队伍情况，雷达站在新规则下的趋势是采用纯视觉方案，放弃使用激光雷达。优势包括一下几点：a、成本低。b、程序更简单，无须进行取深度等操作。c、如果用激光雷达就要进行联合标定，标定完就要保证雷达的相机的相对位置不会发生变化，否则要重新标定，很麻烦。如果只有相机则无须联合标定。d、纯视觉方案识别和定位的连续性更高，更准确。e、目前激光雷达方案效果还挺不错，研究也趋于饱和，要进行大范围的创新很难，如果尝试新方案，有老方案保底。缺点主要有：a、目前队里没有人搞过这个方案，所以一切从头开始，但是RM论坛有一些开源可以借鉴。b、具体方案不知，所以自己搞的话，能不能行得通也不确定。c、对识别的要求更高，需要采用一些预测和追踪算法来优化神经网络的结果。
6，可以在决策方面进行优化，联合自瞄和哨兵作出一套体系，进行更加全面的信息感知和更智能的决策。还可以加一些预警功能，如飞坡预警，英雄边上来敌方步兵的预警等等。

总结：以上所说，如果有任何不懂的地方，一定要弄懂，先自己搜索，实在弄不明白可以问我。这些注意事项全是血的教训，切记啊，只能做的更好，不能降低要求。

